{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a047bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split complete.\n",
      "Train size: 120889 Test size: 30223\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# src/feature_engineering.py\n",
    "# ----------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(filepath=\"../data/processed/fraud_data_processed.csv\"):\n",
    "    \"\"\"Load processed fraud dataset\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['signup_time'] = pd.to_datetime(df['signup_time'])\n",
    "    df['purchase_time'] = pd.to_datetime(df['purchase_time'])\n",
    "    return df\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    \"\"\"Fill missing numeric and categorical values, drop duplicates\"\"\"\n",
    "    num_cols = ['age', 'purchase_value']\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    cat_cols = ['sex', 'source', 'browser']\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def create_time_features(df):\n",
    "    \"\"\"Create time-based features\"\"\"\n",
    "    df['time_diff'] = (df['purchase_time'] - df['signup_time']).dt.total_seconds() / 3600\n",
    "    df['purchase_hour'] = df['purchase_time'].dt.hour\n",
    "    df['purchase_day'] = df['purchase_time'].dt.day_name()\n",
    "    df['is_night'] = df['purchase_hour'].apply(lambda x: 1 if x >= 23 or x <= 5 else 0)\n",
    "    df['is_weekend'] = df['purchase_day'].isin(['Saturday','Sunday']).astype(int)\n",
    "    df['instant_purchase'] = (df['time_diff'] < 1).astype(int)\n",
    "    median_purchase = df['purchase_value'].median()\n",
    "    df['high_value'] = (df['purchase_value'] > median_purchase).astype(int)\n",
    "    return df\n",
    "\n",
    "def create_user_features(df):\n",
    "    \"\"\"User-level frequency and velocity features\"\"\"\n",
    "    user_stats = df.groupby('device_id')['purchase_value'].agg(\n",
    "        user_txn_count='count',\n",
    "        user_total_purchase='sum',\n",
    "        user_avg_purchase='mean'\n",
    "    ).reset_index()\n",
    "    df = df.merge(user_stats, on='device_id', how='left')\n",
    "    return df\n",
    "\n",
    "def encode_and_scale(df):\n",
    "    \"\"\"Encode categorical features and scale numeric features\"\"\"\n",
    "    # Drop high-cardinality columns\n",
    "    df = df.drop(columns=['device_id', 'ip_address'])\n",
    "\n",
    "    # Categorical encoding\n",
    "    cat_cols = ['source','browser','sex','purchase_day']\n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "    # Scale numeric features\n",
    "    num_cols = ['purchase_value','age','time_diff','purchase_hour',\n",
    "                'user_txn_count','user_total_purchase','user_avg_purchase']\n",
    "    scaler = StandardScaler()\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def train_test_split_data(df):\n",
    "    \"\"\"Optional train/test split for modeling\"\"\"\n",
    "    X = df.drop(columns=['class'])\n",
    "    y = df['class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    print(\"Train/Test split complete.\")\n",
    "    print(\"Train size:\", X_train.shape[0], \"Test size:\", X_test.shape[0])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run all feature engineering steps\"\"\"\n",
    "    df = load_data()\n",
    "    df = handle_missing_values(df)\n",
    "    df = create_time_features(df)\n",
    "    df = create_user_features(df)\n",
    "    df = encode_and_scale(df)\n",
    "    train_test_split_data(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b41b352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Countries by Number of Fraudulent Transactions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>fraud_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>52498</td>\n",
       "      <td>5551</td>\n",
       "      <td>0.095626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>20086</td>\n",
       "      <td>1883</td>\n",
       "      <td>0.085712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>10995</td>\n",
       "      <td>1043</td>\n",
       "      <td>0.086642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>6591</td>\n",
       "      <td>715</td>\n",
       "      <td>0.097865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>4013</td>\n",
       "      <td>477</td>\n",
       "      <td>0.106236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korea Republic of</th>\n",
       "      <td>3782</td>\n",
       "      <td>380</td>\n",
       "      <td>0.091302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>2627</td>\n",
       "      <td>348</td>\n",
       "      <td>0.116975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>2861</td>\n",
       "      <td>300</td>\n",
       "      <td>0.094907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>2691</td>\n",
       "      <td>270</td>\n",
       "      <td>0.091185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>3384</td>\n",
       "      <td>262</td>\n",
       "      <td>0.071860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class                  0     1  fraud_rate\n",
       "country                                   \n",
       "United States      52498  5551    0.095626\n",
       "Unknown            20086  1883    0.085712\n",
       "China              10995  1043    0.086642\n",
       "Japan               6591   715    0.097865\n",
       "United Kingdom      4013   477    0.106236\n",
       "Korea Republic of   3782   380    0.091302\n",
       "Canada              2627   348    0.116975\n",
       "France              2861   300    0.094907\n",
       "Brazil              2691   270    0.091185\n",
       "Germany             3384   262    0.071860"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "High-risk countries flagged in 'risk_country' column:\n",
      "['United States', 'Unknown', 'China']\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# Geolocation Integration and Fraud Risk Contextualization\n",
    "# ----------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Load processed fraud dataset\n",
    "fraud_df = pd.read_csv(\"../data/processed/fraud_data_processed.csv\")\n",
    "\n",
    "# Ensure country column exists\n",
    "if 'country' not in fraud_df.columns:\n",
    "    raise ValueError(\"Column 'country' not found. Please ensure country is mapped from IP addresses.\")\n",
    "\n",
    "# Group by country and count fraud vs legit transactions\n",
    "country_fraud_counts = fraud_df.groupby('country')['class'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "# Calculate fraud rate per country\n",
    "country_fraud_counts['fraud_rate'] = country_fraud_counts[1] / (country_fraud_counts[0] + country_fraud_counts[1])\n",
    "\n",
    "# Sort countries by fraud count\n",
    "top_fraud_countries = country_fraud_counts.sort_values(by=1, ascending=False).head(10)\n",
    "\n",
    "# Display top countries by fraud count\n",
    "print(\"Top 10 Countries by Number of Fraudulent Transactions:\")\n",
    "display(top_fraud_countries)\n",
    "\n",
    "# Optional: Flag high-risk countries (top 3 by fraud count)\n",
    "high_risk_countries = top_fraud_countries.index[:3].tolist()\n",
    "fraud_df['risk_country'] = fraud_df['country'].apply(lambda x: 1 if x in high_risk_countries else 0)\n",
    "\n",
    "print(\"\\nHigh-risk countries flagged in 'risk_country' column:\")\n",
    "print(high_risk_countries)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
